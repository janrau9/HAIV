# Dockerfile for the Flask/CUDA model server
# Uses an official PyTorch runtime with CUDA support
FROM pytorch/pytorch:2.2.2-cuda12.1-cudnn8-runtime

WORKDIR /app

# Copy your server code into the container
COPY run.py ./

# Install Python dependencies, including an updated typing_extensions
RUN pip install --no-cache-dir \
    typing_extensions>=4.5.0 \
    torch==2.2.2 \
    transformers==4.51.3 \
    flask \
    flask-cors

# Expose the port the Flask app listens on
EXPOSE 5000

# Launch the server
CMD ["python", "run.py"]